importScripts("https://cdn.jsdelivr.net/npm/@mlc-ai/web-llm@0.2.73/dist/bundle.min.js");let engine=null,isInitialized=!1;async function initializeEngine(e){try{engine=await webllm.CreateMLCEngine(e,{initProgressCallback:e=>{self.postMessage({type:"initProgress",data:e})}}),isInitialized=!0,self.postMessage({type:"initialized",success:!0})}catch(e){self.postMessage({type:"initialized",success:!1,error:e.message})}}async function generateCompletion(e,i,n){if(isInitialized&&engine)try{const t=await engine.chat.completions.create({messages:e,temperature:i,max_tokens:n,stream:!1});self.postMessage({type:"completion",success:!0,data:t.choices[0].message.content})}catch(e){self.postMessage({type:"completion",success:!1,error:e.message})}else self.postMessage({type:"completion",success:!1,error:"Engine not initialized"})}async function resetEngine(){engine&&(await engine.unload(),engine=null,isInitialized=!1),self.postMessage({type:"reset",success:!0})}self.addEventListener("message",async e=>{const{type:i,payload:n}=e.data;switch(i){case"initialize":await initializeEngine(n.modelId);break;case"generate":await generateCompletion(n.messages,n.temperature,n.maxTokens);break;case"reset":await resetEngine();break;default:self.postMessage({type:"error",error:"Unknown message type: "+i})}}),self.postMessage({type:"ready"});